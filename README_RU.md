<div align="center">
  <img src="assets/searching.png" width="30%"/>
</div>

<div align="center">
  <h3> <a href="https://github.com/Solrikk/Echo-Image/blob/main/README.md"> English | <a href="https://github.com/Solrikk/Echo-Image/blob/main/README_RU.md">–†—É—Å—Å–∫–∏–π</a> | <a href="https://github.com/Solrikk/Echo-Image/blob/main/README_GE.md"> Deutsch </a> | <a href="https://github.com/Solrikk/Echo-Image/blob/main/README_JP.md"> Êó•Êú¨Ë™û </a> | <a href="README_KR.md">ÌïúÍµ≠Ïñ¥</a> | <a href="README_CN.md">‰∏≠Êñá</a> </h3>
</div>

-----------------

# Echo-Image ‚ö°Ô∏è

 **_EchoImage:_** —ç—Ç–æ –ø–µ—Ä–µ–¥–æ–≤–∞—è –ø–ª–∞—Ç—Ñ–æ—Ä–º–∞, –ø—Ä–µ–¥–Ω–∞–∑–Ω–∞—á–µ–Ω–Ω–∞—è –¥–ª—è —Ç–æ—á–Ω–æ–≥–æ –ø–æ–∏—Å–∫–∞ –ø–æ—Ö–æ–∂–∏—Ö –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π. –ò—Å–ø–æ–ª—å–∑—É—è –∞–ª–≥–æ—Ä–∏—Ç–º—ã —Å—Ä–∞–≤–Ω–µ–Ω–∏—è —Å—Ç—Ä—É–∫—Ç—É—Ä–Ω–æ–≥–æ —Å—Ö–æ–¥—Å—Ç–≤–∞ –∏ —Å–æ–ø–æ—Å—Ç–∞–≤–ª–µ–Ω–∏—è –∫–ª—é—á–µ–≤—ã—Ö —Ç–æ—á–µ–∫, EchoImage –æ–±–µ—Å–ø–µ—á–∏–≤–∞–µ—Ç –±—ã—Å—Ç—Ä—ã–π –∏ —Ç–æ—á–Ω—ã–π –º–µ—Ç–æ–¥ —Å—Ä–∞–≤–Ω–µ–Ω–∏—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π. –ü—Ä–∏–ª–æ–∂–µ–Ω–∏–µ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç –∑–∞–≥—Ä—É–∑–∫—É –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –Ω–∞–ø—Ä—è–º—É—é –∏–ª–∏ —á–µ—Ä–µ–∑ URL, —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ –ø—Ä–æ—Å–º–∞—Ç—Ä–∏–≤–∞—è –æ–≥—Ä–æ–º–Ω—É—é –±–∞–∑—É –¥–∞–Ω–Ω—ã—Ö –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –¥–ª—è –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è –Ω–∞–∏–ª—É—á—à–∏—Ö —Å–æ–≤–ø–∞–¥–µ–Ω–∏–π. –ë–ª–∞–≥–æ–¥–∞—Ä—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—é –∞—Å–∏–Ω—Ö—Ä–æ–Ω–Ω—ã—Ö —Ç–µ—Ö–Ω–æ–ª–æ–≥–∏–π, EchoImage –æ–±–µ—Å–ø–µ—á–∏–≤–∞–µ—Ç –±—ã—Å—Ç—Ä—É—é –æ–±—Ä–∞–±–æ—Ç–∫—É, –ø—Ä–µ–¥–ª–∞–≥–∞—è –±–µ—Å—à–æ–≤–Ω—ã–π –∏ —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω—ã–π –æ–ø—ã—Ç –≤–∏–∑—É–∞–ª—å–Ω–æ–≥–æ –ø–æ–∏—Å–∫–∞.

**_–í—ã –º–æ–∂–µ—Ç–µ —Å–æ–∑–¥–∞—Ç—å –±–∞–∑—É –¥–∞–Ω–Ω—ã—Ö –∑–¥–µ—Å—å_** - ([–ø–æ–¥—Ä–æ–±–Ω–æ—Å—Ç–∏](https://github.com/Solrikk/ImageSpaceDB))

## –í–æ–∑–º–æ–∂–Ω–æ—Å—Ç–∏
- **_–ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç –º–Ω–æ–∂–µ—Å—Ç–≤–æ —Ç–µ—Ö–Ω–æ–ª–æ–≥–∏–π_** ‚òÑÔ∏è

    _**Python**_ —Å –±–∏–±–ª–∏–æ—Ç–µ–∫–∞–º–∏::
  - `FastAPI` –¥–ª—è –≤–µ–±-—Ñ—Ä–µ–π–º–≤–æ—Ä–∫–∞.
  - `aiohttp` –¥–ª—è –∞—Å–∏–Ω—Ö—Ä–æ–Ω–Ω—ã—Ö HTTP-–∑–∞–ø—Ä–æ—Å–æ–≤.
  - `cv2` (OpenCV) –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π.
  - `numpy` –¥–ª—è –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è —á–∏—Å–ª–æ–≤—ã—Ö –æ–ø–µ—Ä–∞—Ü–∏–π.
  - `skimage` –¥–ª—è –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã—Ö –º–µ—Ç–æ–¥–æ–≤ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π.

- **_–ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç –º–Ω–æ–∂–µ—Å—Ç–≤–æ –∏–Ω–¥–µ–∫—Å–æ–≤_** üöÄ

  - `–ò–Ω–¥–µ–∫—Å —Å—Ç—Ä—É–∫—Ç—É—Ä–Ω–æ–≥–æ —Å—Ö–æ–¥—Å—Ç–≤–∞ (SSIM)` ([–ø–æ–¥—Ä–æ–±–Ω–æ—Å—Ç–∏](https://en.wikipedia.org/wiki/Structural_similarity_index_measure))
  - `–°–æ–ø–æ—Å—Ç–∞–≤–ª–µ–Ω–∏–µ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º –¥–µ—Å–∫—Ä–∏–ø—Ç–æ—Ä–∞ ORB (Oriented FAST and Rotated BRIEF)` ([–ø–æ–¥—Ä–æ–±–Ω–æ—Å—Ç–∏](https://en.wikipedia.org/wiki/Oriented_FAST_and_rotated_BRIEF))
  - `–ò–∑–º–µ–Ω–µ–Ω–∏–µ —Ä–∞–∑–º–µ—Ä–∞ –∏ –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ –≤ –æ—Ç—Ç–µ–Ω–∫–∏ —Å–µ—Ä–æ–≥–æ` ([–ø–æ–¥—Ä–æ–±–Ω–æ—Å—Ç–∏](https://en.wikipedia.org/wiki/Grayscale))
  - `–•–µ—à–∏—Ä–æ–≤–∞–Ω–∏–µ –¥–ª—è –∏–¥–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ü–∏–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π`
    
# –ü—Ä–∏–º–µ—Ä—ã
`–ü—Ä–∏–º–µ—Ä –Ω–∞ Python` [[–±–æ–ª—å—à–µ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏](https://github.com/Solrikk/EchoImage/blob/main/main.py)]

```Python
async def process_image(session, image_entry, target_image):
  try:
    current_image = await download_image(session, image_entry["url"])
    optimal_size = max(max(target_image.shape[:2]),
                       max(current_image.shape[:2]))
    optimal_size = min(1024, optimal_size)
    target_image_resized = cv2.resize(target_image,
                                      (optimal_size, optimal_size))
    current_image_resized = cv2.resize(current_image,
                                       (optimal_size, optimal_size))
    target_gray = cv2.cvtColor(target_image_resized, cv2.COLOR_BGR2GRAY)
    current_gray = cv2.cvtColor(current_image_resized, cv2.COLOR_BGR2GRAY)
    ssim_index = ssim(target_gray, current_gray)
    orb = cv2.ORB_create(nfeatures=500)
    target_keypoints, target_descriptors = orb.detectAndCompute(
        target_gray, None)
    current_keypoints, current_descriptors = orb.detectAndCompute(
        current_gray, None)
    if target_descriptors is None or current_descriptors is None:
      return (0, image_entry["url"])
    index_params = dict(algorithm=6,
                        table_number=6,
                        key_size=12,
                        multi_probe_level=1)
    search_params = dict(checks=50)
    flann = cv2.FlannBasedMatcher(index_params, search_params)
```

#

![image](https://wikimedia.org/api/rest_v1/media/math/render/svg/4203f29f732e5cdc9d8a95907ef6d8e12f08ca09)

SSIM —Å—Ä–∞–≤–Ω–∏–≤–∞–µ—Ç –ø–∞—Ç—Ç–µ—Ä–Ω—ã –∏–∑–º–µ–Ω–µ–Ω–∏–π –∏–Ω—Ç–µ–Ω—Å–∏–≤–Ω–æ—Å—Ç–∏ –ø–∏–∫—Å–µ–ª–µ–π, –∫–æ—Ç–æ—Ä—ã–µ —è–≤–ª—è—é—Ç—Å—è –≤–∞–∂–Ω—ã–º–∏ –∞—Ç—Ä–∏–±—É—Ç–∞–º–∏ –¥–ª—è —á–µ–ª–æ–≤–µ—á–µ—Å–∫–æ–≥–æ –∑—Ä–µ–Ω–∏—è. –û—Ü–µ–Ω–∫–∞ SSIM –Ω–∞—Ö–æ–¥–∏—Ç—Å—è –≤ –¥–∏–∞–ø–∞–∑–æ–Ω–µ –æ—Ç `-1 –¥–æ +1`, –≥–¥–µ `–∑–Ω–∞—á–µ–Ω–∏–µ 1` —É–∫–∞–∑—ã–≤–∞–µ—Ç –Ω–∞ –∏–¥–µ–Ω—Ç–∏—á–Ω—ã–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è. –ü—Ä–æ—Ü–µ—Å—Å –º–æ–∂–Ω–æ —Ä–∞–∑–±–∏—Ç—å –Ω–∞ —Ç—Ä–∏ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–∞:

<img src="https://github.com/Solrikk/EchoImage/blob/main/assets/ssim/ssim2.png" width="95%" /> 

1) **_–°—Ä–∞–≤–Ω–µ–Ω–∏–µ —è—Ä–∫–æ—Å—Ç–∏_** –ø–æ–∑–≤–æ–ª—è–µ—Ç –æ—Ü–µ–Ω–∏—Ç—å –æ–±—â—É—é —è—Ä–∫–æ—Å—Ç—å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π. –Ø—Ä–∫–æ—Å—Ç—å –≤ SSIM –∏–∑–º–µ—Ä—è–µ—Ç—Å—è –∫–∞–∫ —Å—Ä–µ–¥–Ω–µ–µ –≤—Å–µ—Ö –∑–Ω–∞—á–µ–Ω–∏–π –ø–∏–∫—Å–µ–ª–µ–π.

```Python
target_gray = cv2.cvtColor(target_image_resized, cv2.COLOR_BGR2GRAY)
current_gray = cv2.cvtColor(current_image_resized, cv2.COLOR_BGR2GRAY)
ssim_index = ssim(target_gray, current_gray)
```

2) **_–°—Ä–∞–≤–Ω–µ–Ω–∏–µ –∫–æ–Ω—Ç—Ä–∞—Å—Ç–∞_** –∏–∑–º–µ—Ä—è–µ—Ç—Å—è —á–µ—Ä–µ–∑ –¥–∏—Å–ø–µ—Ä—Å–∏—é –∏–Ω—Ç–µ–Ω—Å–∏–≤–Ω–æ—Å—Ç–∏ –ø–∏–∫—Å–µ–ª–µ–π (–æ—Ç–∫–ª–æ–Ω–µ–Ω–∏—è –æ—Ç —Å—Ä–µ–¥–Ω–µ–≥–æ –∑–Ω–∞—á–µ–Ω–∏—è), –ø–æ–Ω–∏–º–∞—è, –Ω–∞—Å–∫–æ–ª—å–∫–æ –ø–æ—Ö–æ–∂–∏ –ø–∞—Ç—Ç–µ—Ä–Ω—ã —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è —Å–≤–µ—Ç–∞ –∏ —Ç–µ–Ω–∏ –º–µ–∂–¥—É –¥–≤—É–º—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è–º–∏.
3) **_–°—Ä–∞–≤–Ω–µ–Ω–∏–µ —Å—Ç—Ä—É–∫—Ç—É—Ä—ã_** c—Ä–∞–≤–Ω–∏–≤–∞–µ—Ç –ø–∞—Ç—Ç–µ—Ä–Ω—ã –ø—Ä–æ—Å—Ç—Ä–∞–Ω—Å—Ç–≤–µ–Ω–Ω–æ–≥–æ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è –ø–∏–∫—Å–µ–ª–µ–π, –∏–≥–Ω–æ—Ä–∏—Ä—É—è –∏–∑–º–µ–Ω–µ–Ω–∏—è –≤ —è—Ä–∫–æ—Å—Ç–∏ –∏ –∫–æ–Ω—Ç—Ä–∞—Å—Ç–µ. –≠—Ç–æ –¥–µ–ª–∞–µ—Ç—Å—è –ø—É—Ç–µ–º —Ä–∞—Å—á–µ—Ç–∞ –∫–æ–≤–∞—Ä–∏–∞—Ü–∏–∏ –º–µ–∂–¥—É –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è–º–∏ –æ—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω–æ –∏—Ö –ª–æ–∫–∞–ª—å–Ω—ã—Ö —Å—Ä–µ–¥–Ω–∏—Ö –∑–Ω–∞—á–µ–Ω–∏–π.

![image](https://wikimedia.org/api/rest_v1/media/math/render/svg/96b4f1c3840c3707a93197798dcbfbfff24fa92b)
![image](https://wikimedia.org/api/rest_v1/media/math/render/svg/fcda97086476fa420b3b06568a0d202980a600d0)
![image](https://wikimedia.org/api/rest_v1/media/math/render/svg/1aebd62ba5b7e6ae47780ccfa659333f078d6eac)

–î–ª—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –ò–Ω–¥–µ–∫—Å —Å—Ç—Ä—É–∫—Ç—É—Ä–Ω–æ–≥–æ —Å—Ö–æ–¥—Å—Ç–≤–∞ **(SSIM)** –¥–ª—è –æ—Ü–µ–Ω–∫–∏ —Å—Ö–æ–¥—Å—Ç–≤–∞ –º–µ–∂–¥—É –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è–º–∏, –∞ —Ç–∞–∫–∂–µ –∞–ª–≥–æ—Ä–∏—Ç–º **ORB (Oriented FAST and Rotated BRIEF)** –¥–ª—è –æ–±–Ω–∞—Ä—É–∂–µ–Ω–∏—è –∫–ª—é—á–µ–≤—ã—Ö —Ç–æ—á–µ–∫ –∏ –∏—Ö –æ–ø–∏—Å–∞–Ω–∏–π.

## _ORB (Oriented FAST and Rotated BRIEF)_ 
ORB –º–µ—Ç–æ–¥, –∏—Å–ø–æ–ª—å–∑—É–µ–º—ã–π –≤ –∫–æ–º–ø—å—é—Ç–µ—Ä–Ω–æ–º –∑—Ä–µ–Ω–∏–∏, –æ—Å–æ–±–µ–Ω–Ω–æ –ø–æ–ø—É–ª—è—Ä–Ω—ã–π –¥–ª—è –∑–∞–¥–∞—á, —Å–≤—è–∑–∞–Ω–Ω—ã—Ö —Å —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏–µ–º –æ–±—ä–µ–∫—Ç–æ–≤, —Å–æ–ø–æ—Å—Ç–∞–≤–ª–µ–Ω–∏–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –∏ –æ—Ç—Å–ª–µ–∂–∏–≤–∞–Ω–∏–µ–º. –≠—Ç–æ—Ç –º–µ—Ç–æ–¥ —Å–æ—Å—Ä–µ–¥–æ—Ç–æ—á–µ–Ω –Ω–∞ –±—ã—Å—Ç—Ä–æ–º –ø–æ–∏—Å–∫–µ –∫–ª—é—á–µ–≤—ã—Ö —Ç–æ—á–µ–∫ –Ω–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è—Ö –∏ –æ–ø–∏—Å–∞–Ω–∏–∏ –∏—Ö —Ç–∞–∫–∏–º –æ–±—Ä–∞–∑–æ–º, —á—Ç–æ–±—ã –º–æ–∂–Ω–æ –±—ã–ª–æ —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ —Å—Ä–∞–≤–Ω–∏–≤–∞—Ç—å –∏—Ö. ORB –æ–±–µ—Å–ø–µ—á–∏–≤–∞–µ—Ç –±—ã—Å—Ç—Ä—ã–π –∏ —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω—ã–π —Å–ø–æ—Å–æ–± —Å–æ–ø–æ—Å—Ç–∞–≤–ª–µ–Ω–∏—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π, –Ω–µ—Å–º–æ—Ç—Ä—è –Ω–∞ –∏–∑–º–µ–Ω–µ–Ω–∏—è –≤ —É–≥–ª–µ –æ–±–∑–æ—Ä–∞, –º–∞—Å—à—Ç–∞–±–µ –∏–ª–∏ –æ—Å–≤–µ—â–µ–Ω–∏–∏.

<img src="https://github.com/Solrikk/EchoImage/blob/main/assets/ORB/ORB3.png" width="95%" /> 

1) **Oriented FAST (Features from Accelerated Segment Test):** This part is responsible for detecting points of interest (or key points) on the image. It quickly identifies corners or edges that stand out in comparison to their surrounding areas. This way, significant or unique sections of the image can be identified.

2) **Rotated BRIEF (Binary Robust Independent Elementary Features):** After key points have been found, it's necessary to create a description of each to allow comparison with key points from another image. BRIEF generates a brief binary description of the points but lacks resistance to image rotation. This is where the "rotated" part comes in - ORB adds the ability to stably describe points even when images are rotated.

By combining these two approaches, ORB provides a fast and efficient way of matching images despite changes in viewing angle, scale, or lighting.

_Using the ORB algorithm, key points and descriptors are determined for both the current and target images._

The found key points are compared with each other to determine matches. These matches allow assessing the similarity of images from a perspective other than SSIM. The final similarity score is calculated as the average between the SSIM score and the relative number of matching key points (using the ORB algorithm), providing a comprehensive approach to analyzing the similarity of images.

EchoImage application, both the SSIM and ORB methods are utilized to find images that are similar to an uploaded image. Here's a simplified explanation of how each method works in the context of your application and contributes to finding similar images:

## How SSIM Works in EchoImage:
1) **_Resizing Images:_** When comparing the uploaded image to each image in the database, both images are resized to the same dimensions `(256x256 pixels)`. This standardizes the comparison, making it fair and more efficient since we're working with images of the same size.

2) **_Converting to Grayscale:_** Both images are converted to grayscale. This simplifies the comparison by focusing on the structure and intensity of light rather than being distracted by color differences.

3) **_Structural Similarity Comparison:_** The SSIM method then compares these grayscale images to assess their structural similarity. This involves analyzing how similar the patterns of light and shadow are between the two images, giving a score that reflects their similarity. A high score means the images are structurally similar.

## How ORB Works in EchoImage:
1) **_Detecting Key Points:_** ORB first identifies key points in both the uploaded image and each database image. These key points are distinctive spots that can be easily recognized and compared between images, such as corners and interesting textures.

2) **_Describing Key Points:_** For each key point detected, ORB generates a unique descriptor that summarizes the key point's characteristics. This descriptor is made rotation-invariant, meaning it describes the key point in a way that's consistent even if the image is rotated.

3) **_Matching Key Points:_** The application then matches key points between the uploaded image and each database image using these descriptors. The matching process involves finding key points in the database image that have descriptors similar to those in the uploaded image.

4) **_Scoring Matches:_** The more key points that match between two images, the higher the score of similarity based on ORB. This score reflects how many distinctive features are shared between the images.

## Combining SSIM and ORB:
 After calculating similarity scores using both SSIM and ORB for each image comparison, Harmony-Image averages these scores to get a final measure of similarity.
Images from the database are then ranked based on their final similarity scores, and the top 5 most similar images are selected.

## Final Selection of Similar Images:
The application filters out duplicate URLs to ensure a diverse set of similar images.
 It returns URLs of the top similar images, which can then be presented to the user.
 In essence, your application uses a combination of structural analysis (SSIM) and feature matching (ORB) to find and rank images in your database that are most similar to an image uploaded by the user. This dual approach leverages the strengths of both methods, ensuring a robust and nuanced comparison that goes beyond simple pixel-by-pixel analysis.
